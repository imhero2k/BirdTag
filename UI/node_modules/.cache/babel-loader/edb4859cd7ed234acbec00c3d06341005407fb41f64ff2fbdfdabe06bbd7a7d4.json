{"ast":null,"code":"import _objectSpread from \"/Users/saisaran/Desktop/BirdTag/UI/node_modules/@babel/runtime/helpers/esm/objectSpread2.js\";\nimport { UPLOADS_STORAGE_KEY } from '../../../../utils/constants.mjs';\nimport '../../../../utils/client/s3data/base.mjs';\nimport '../../../../utils/client/s3data/getObject.mjs';\nimport '../../../../utils/client/s3data/listObjectsV2.mjs';\nimport '../../../../utils/client/s3data/putObject.mjs';\nimport '../../../../utils/client/s3data/createMultipartUpload.mjs';\nimport '../../../../utils/client/s3data/uploadPart.mjs';\nimport '../../../../utils/client/s3data/completeMultipartUpload.mjs';\nimport { listParts } from '../../../../utils/client/s3data/listParts.mjs';\nimport '../../../../utils/client/s3data/abortMultipartUpload.mjs';\nimport '../../../../utils/client/s3data/copyObject.mjs';\nimport '../../../../utils/client/s3data/headObject.mjs';\nimport '../../../../utils/client/s3data/deleteObject.mjs';\nimport '../../../../../../errors/types/validation.mjs';\nimport '@aws-amplify/core/internals/utils';\nimport { logger } from '../../../../../../utils/logger.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst ONE_HOUR = 1000 * 60 * 60;\n/**\n * Find the cached multipart upload id and get the parts that have been uploaded\n * with ListParts API. If the cached upload is expired(1 hour), return null.\n */\nconst findCachedUploadPartsAndEvictExpired = async _ref => {\n  let {\n    resumableUploadsCache,\n    cacheKey,\n    s3Config,\n    bucket,\n    finalKey\n  } = _ref;\n  const allCachedUploads = await listCachedUploadTasks(resumableUploadsCache);\n  // Evict all outdated uploads.\n  const validCachedUploads = Object.fromEntries(Object.entries(allCachedUploads).filter(_ref2 => {\n    let [_, cacheValue] = _ref2;\n    return cacheValue.lastTouched >= Date.now() - ONE_HOUR;\n  }));\n  if (Object.keys(validCachedUploads).length !== Object.keys(allCachedUploads).length) {\n    await resumableUploadsCache.setItem(UPLOADS_STORAGE_KEY, JSON.stringify(validCachedUploads));\n  }\n  if (!validCachedUploads[cacheKey]) {\n    return null;\n  }\n  const cachedUpload = validCachedUploads[cacheKey];\n  cachedUpload.lastTouched = Date.now();\n  await resumableUploadsCache.setItem(UPLOADS_STORAGE_KEY, JSON.stringify(validCachedUploads));\n  try {\n    const {\n      Parts = []\n    } = await listParts(s3Config, {\n      Bucket: bucket,\n      Key: finalKey,\n      UploadId: cachedUpload.uploadId\n    });\n    return {\n      parts: Parts,\n      uploadId: cachedUpload.uploadId,\n      finalCrc32: cachedUpload.finalCrc32\n    };\n  } catch (e) {\n    logger.debug('failed to list cached parts, removing cached upload.');\n    await removeCachedUpload(resumableUploadsCache, cacheKey);\n    return null;\n  }\n};\nconst listCachedUploadTasks = async resumableUploadsCache => {\n  try {\n    var _await$resumableUploa;\n    return JSON.parse((_await$resumableUploa = await resumableUploadsCache.getItem(UPLOADS_STORAGE_KEY)) !== null && _await$resumableUploa !== void 0 ? _await$resumableUploa : '{}');\n  } catch (e) {\n    logger.debug('failed to parse cached uploads record.');\n    return {};\n  }\n};\n/**\n * Serialize the uploadData API options to string so it can be hashed.\n */\nconst serializeUploadOptions = function () {\n  let options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n  const unserializableOptionProperties = ['onProgress', 'resumableUploadsCache',\n  // Internally injected implementation not set by customers\n  'locationCredentialsProvider' // Internally injected implementation not set by customers\n  ];\n  const serializableOptionEntries = Object.entries(options).filter(_ref3 => {\n    let [key] = _ref3;\n    return !unserializableOptionProperties.includes(key);\n  });\n  if (options.checksumAlgorithm === 'crc-32') {\n    // Additional options to differentiate the upload cache created before introducing the full-object checksum and\n    // after. If full-object checksum is enabled, the previous upload caches that created with composite checksum should\n    // be ignored.\n    serializableOptionEntries.push(['checksumType', 'FULL_OBJECT']);\n  }\n  const serializableOptions = Object.fromEntries(serializableOptionEntries);\n  return JSON.stringify(serializableOptions);\n};\n/**\n * Get the cache key of a multipart upload. Data source cached by different: size, content type, bucket, access level,\n * key. If the data source is a File instance, the upload is additionally indexed by file name and last modified time.\n * So the library always created a new multipart upload if the file is modified.\n */\nconst getUploadsCacheKey = _ref4 => {\n  var _ref5;\n  let {\n    file,\n    size,\n    contentType,\n    bucket,\n    accessLevel,\n    key,\n    optionsHash\n  } = _ref4;\n  let levelStr;\n  const resolvedContentType = (_ref5 = contentType !== null && contentType !== void 0 ? contentType : file === null || file === void 0 ? void 0 : file.type) !== null && _ref5 !== void 0 ? _ref5 : 'application/octet-stream';\n  // If no access level is defined, we're using custom gen2 access rules\n  if (accessLevel === undefined) {\n    levelStr = 'custom';\n  } else {\n    levelStr = accessLevel === 'guest' ? 'public' : accessLevel;\n  }\n  const baseId = \"\".concat(optionsHash, \"_\").concat(size, \"_\").concat(resolvedContentType, \"_\").concat(bucket, \"_\").concat(levelStr, \"_\").concat(key);\n  if (file) {\n    return \"\".concat(file.name, \"_\").concat(file.lastModified, \"_\").concat(baseId);\n  } else {\n    return baseId;\n  }\n};\nconst cacheMultipartUpload = async (resumableUploadsCache, cacheKey, fileMetadata) => {\n  const cachedUploads = await listCachedUploadTasks(resumableUploadsCache);\n  cachedUploads[cacheKey] = _objectSpread(_objectSpread({}, fileMetadata), {}, {\n    lastTouched: Date.now()\n  });\n  await resumableUploadsCache.setItem(UPLOADS_STORAGE_KEY, JSON.stringify(cachedUploads));\n};\nconst removeCachedUpload = async (resumableUploadsCache, cacheKey) => {\n  const cachedUploads = await listCachedUploadTasks(resumableUploadsCache);\n  delete cachedUploads[cacheKey];\n  await resumableUploadsCache.setItem(UPLOADS_STORAGE_KEY, JSON.stringify(cachedUploads));\n};\nexport { cacheMultipartUpload, findCachedUploadPartsAndEvictExpired, getUploadsCacheKey, removeCachedUpload, serializeUploadOptions };","map":{"version":3,"names":["ONE_HOUR","findCachedUploadPartsAndEvictExpired","_ref","resumableUploadsCache","cacheKey","s3Config","bucket","finalKey","allCachedUploads","listCachedUploadTasks","validCachedUploads","Object","fromEntries","entries","filter","_ref2","_","cacheValue","lastTouched","Date","now","keys","length","setItem","UPLOADS_STORAGE_KEY","JSON","stringify","cachedUpload","Parts","listParts","Bucket","Key","UploadId","uploadId","parts","finalCrc32","e","logger","debug","removeCachedUpload","_await$resumableUploa","parse","getItem","serializeUploadOptions","options","arguments","undefined","unserializableOptionProperties","serializableOptionEntries","_ref3","key","includes","checksumAlgorithm","push","serializableOptions","getUploadsCacheKey","_ref4","_ref5","file","size","contentType","accessLevel","optionsHash","levelStr","resolvedContentType","type","baseId","concat","name","lastModified","cacheMultipartUpload","fileMetadata","cachedUploads","_objectSpread"],"sources":["/Users/saisaran/Desktop/BirdTag/UI/node_modules/@aws-amplify/storage/src/providers/s3/apis/internal/uploadData/multipart/uploadCache.ts"],"sourcesContent":["// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nimport { UPLOADS_STORAGE_KEY } from '../../../../utils/constants';\nimport { listParts } from '../../../../utils/client/s3data';\nimport { logger } from '../../../../../../utils';\nconst ONE_HOUR = 1000 * 60 * 60;\n/**\n * Find the cached multipart upload id and get the parts that have been uploaded\n * with ListParts API. If the cached upload is expired(1 hour), return null.\n */\nexport const findCachedUploadPartsAndEvictExpired = async ({ resumableUploadsCache, cacheKey, s3Config, bucket, finalKey, }) => {\n    const allCachedUploads = await listCachedUploadTasks(resumableUploadsCache);\n    // Evict all outdated uploads.\n    const validCachedUploads = Object.fromEntries(Object.entries(allCachedUploads).filter(([_, cacheValue]) => cacheValue.lastTouched >= Date.now() - ONE_HOUR));\n    if (Object.keys(validCachedUploads).length !==\n        Object.keys(allCachedUploads).length) {\n        await resumableUploadsCache.setItem(UPLOADS_STORAGE_KEY, JSON.stringify(validCachedUploads));\n    }\n    if (!validCachedUploads[cacheKey]) {\n        return null;\n    }\n    const cachedUpload = validCachedUploads[cacheKey];\n    cachedUpload.lastTouched = Date.now();\n    await resumableUploadsCache.setItem(UPLOADS_STORAGE_KEY, JSON.stringify(validCachedUploads));\n    try {\n        const { Parts = [] } = await listParts(s3Config, {\n            Bucket: bucket,\n            Key: finalKey,\n            UploadId: cachedUpload.uploadId,\n        });\n        return {\n            parts: Parts,\n            uploadId: cachedUpload.uploadId,\n            finalCrc32: cachedUpload.finalCrc32,\n        };\n    }\n    catch (e) {\n        logger.debug('failed to list cached parts, removing cached upload.');\n        await removeCachedUpload(resumableUploadsCache, cacheKey);\n        return null;\n    }\n};\nconst listCachedUploadTasks = async (resumableUploadsCache) => {\n    try {\n        return JSON.parse((await resumableUploadsCache.getItem(UPLOADS_STORAGE_KEY)) ?? '{}');\n    }\n    catch (e) {\n        logger.debug('failed to parse cached uploads record.');\n        return {};\n    }\n};\n/**\n * Serialize the uploadData API options to string so it can be hashed.\n */\nexport const serializeUploadOptions = (options = {}) => {\n    const unserializableOptionProperties = [\n        'onProgress',\n        'resumableUploadsCache', // Internally injected implementation not set by customers\n        'locationCredentialsProvider', // Internally injected implementation not set by customers\n    ];\n    const serializableOptionEntries = Object.entries(options).filter(([key]) => !unserializableOptionProperties.includes(key));\n    if (options.checksumAlgorithm === 'crc-32') {\n        // Additional options to differentiate the upload cache created before introducing the full-object checksum and\n        // after. If full-object checksum is enabled, the previous upload caches that created with composite checksum should\n        // be ignored.\n        serializableOptionEntries.push(['checksumType', 'FULL_OBJECT']);\n    }\n    const serializableOptions = Object.fromEntries(serializableOptionEntries);\n    return JSON.stringify(serializableOptions);\n};\n/**\n * Get the cache key of a multipart upload. Data source cached by different: size, content type, bucket, access level,\n * key. If the data source is a File instance, the upload is additionally indexed by file name and last modified time.\n * So the library always created a new multipart upload if the file is modified.\n */\nexport const getUploadsCacheKey = ({ file, size, contentType, bucket, accessLevel, key, optionsHash, }) => {\n    let levelStr;\n    const resolvedContentType = contentType ?? file?.type ?? 'application/octet-stream';\n    // If no access level is defined, we're using custom gen2 access rules\n    if (accessLevel === undefined) {\n        levelStr = 'custom';\n    }\n    else {\n        levelStr = accessLevel === 'guest' ? 'public' : accessLevel;\n    }\n    const baseId = `${optionsHash}_${size}_${resolvedContentType}_${bucket}_${levelStr}_${key}`;\n    if (file) {\n        return `${file.name}_${file.lastModified}_${baseId}`;\n    }\n    else {\n        return baseId;\n    }\n};\nexport const cacheMultipartUpload = async (resumableUploadsCache, cacheKey, fileMetadata) => {\n    const cachedUploads = await listCachedUploadTasks(resumableUploadsCache);\n    cachedUploads[cacheKey] = {\n        ...fileMetadata,\n        lastTouched: Date.now(),\n    };\n    await resumableUploadsCache.setItem(UPLOADS_STORAGE_KEY, JSON.stringify(cachedUploads));\n};\nexport const removeCachedUpload = async (resumableUploadsCache, cacheKey) => {\n    const cachedUploads = await listCachedUploadTasks(resumableUploadsCache);\n    delete cachedUploads[cacheKey];\n    await resumableUploadsCache.setItem(UPLOADS_STORAGE_KEY, JSON.stringify(cachedUploads));\n};\n"],"mappings":";;;;;;;;;;;;;;;;;;AAAA;AACA;AAIA,MAAMA,QAAQ,GAAG,IAAI,GAAG,EAAE,GAAG,EAAE;AAC/B;AACA;AACA;AACA;AACY,MAACC,oCAAoC,GAAG,MAAAC,IAAA,IAA4E;EAAA,IAArE;IAAEC,qBAAqB;IAAEC,QAAQ;IAAEC,QAAQ;IAAEC,MAAM;IAAEC;EAAQ,CAAG,GAAAL,IAAA;EACvH,MAAMM,gBAAgB,GAAG,MAAMC,qBAAqB,CAACN,qBAAqB,CAAC;EAC/E;EACI,MAAMO,kBAAkB,GAAGC,MAAM,CAACC,WAAW,CAACD,MAAM,CAACE,OAAO,CAACL,gBAAgB,CAAC,CAACM,MAAM,CAACC,KAAA;IAAA,IAAC,CAACC,CAAC,EAAEC,UAAU,CAAC,GAAAF,KAAA;IAAA,OAAKE,UAAU,CAACC,WAAW,IAAIC,IAAI,CAACC,GAAG,EAAE,GAAGpB,QAAQ;EAAA,EAAC,CAAC;EAC5J,IAAIW,MAAM,CAACU,IAAI,CAACX,kBAAkB,CAAC,CAACY,MAAM,KACtCX,MAAM,CAACU,IAAI,CAACb,gBAAgB,CAAC,CAACc,MAAM,EAAE;IACtC,MAAMnB,qBAAqB,CAACoB,OAAO,CAACC,mBAAmB,EAAEC,IAAI,CAACC,SAAS,CAAChB,kBAAkB,CAAC,CAAC;EACpG;EACI,IAAI,CAACA,kBAAkB,CAACN,QAAQ,CAAC,EAAE;IAC/B,OAAO,IAAI;EACnB;EACI,MAAMuB,YAAY,GAAGjB,kBAAkB,CAACN,QAAQ,CAAC;EACjDuB,YAAY,CAACT,WAAW,GAAGC,IAAI,CAACC,GAAG,EAAE;EACrC,MAAMjB,qBAAqB,CAACoB,OAAO,CAACC,mBAAmB,EAAEC,IAAI,CAACC,SAAS,CAAChB,kBAAkB,CAAC,CAAC;EAC5F,IAAI;IACA,MAAM;MAAEkB,KAAK,GAAG;IAAE,CAAE,GAAG,MAAMC,SAAS,CAACxB,QAAQ,EAAE;MAC7CyB,MAAM,EAAExB,MAAM;MACdyB,GAAG,EAAExB,QAAQ;MACbyB,QAAQ,EAAEL,YAAY,CAACM;IACnC,CAAS,CAAC;IACF,OAAO;MACHC,KAAK,EAAEN,KAAK;MACZK,QAAQ,EAAEN,YAAY,CAACM,QAAQ;MAC/BE,UAAU,EAAER,YAAY,CAACQ;IACrC,CAAS;EACT,EACI,OAAOC,CAAC,EAAE;IACNC,MAAM,CAACC,KAAK,CAAC,sDAAsD,CAAC;IACpE,MAAMC,kBAAkB,CAACpC,qBAAqB,EAAEC,QAAQ,CAAC;IACzD,OAAO,IAAI;EACnB;AACA;AACA,MAAMK,qBAAqB,GAAG,MAAON,qBAAqB,IAAK;EAC3D,IAAI;IAAA,IAAAqC,qBAAA;IACA,OAAOf,IAAI,CAACgB,KAAK,EAAAD,qBAAA,GAAE,MAAMrC,qBAAqB,CAACuC,OAAO,CAAClB,mBAAmB,CAAC,cAAAgB,qBAAA,cAAAA,qBAAA,GAAK,IAAI,CAAC;EAC7F,EACI,OAAOJ,CAAC,EAAE;IACNC,MAAM,CAACC,KAAK,CAAC,wCAAwC,CAAC;IACtD,OAAO,EAAE;EACjB;AACA,CAAC;AACD;AACA;AACA;AACY,MAACK,sBAAsB,GAAG,SAAAA,CAAA,EAAkB;EAAA,IAAjBC,OAAO,GAAAC,SAAA,CAAAvB,MAAA,QAAAuB,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAG,EAAE;EAC/C,MAAME,8BAA8B,GAAG,CACnC,YAAY,EACZ,uBAAuB;EAAA;EACvB,6BAA6B;EAAA,CAChC;EACD,MAAMC,yBAAyB,GAAGrC,MAAM,CAACE,OAAO,CAAC+B,OAAO,CAAC,CAAC9B,MAAM,CAACmC,KAAA;IAAA,IAAC,CAACC,GAAG,CAAC,GAAAD,KAAA;IAAA,OAAK,CAACF,8BAA8B,CAACI,QAAQ,CAACD,GAAG,CAAC;EAAA,EAAC;EAC1H,IAAIN,OAAO,CAACQ,iBAAiB,KAAK,QAAQ,EAAE;IAChD;IACA;IACA;IACQJ,yBAAyB,CAACK,IAAI,CAAC,CAAC,cAAc,EAAE,aAAa,CAAC,CAAC;EACvE;EACI,MAAMC,mBAAmB,GAAG3C,MAAM,CAACC,WAAW,CAACoC,yBAAyB,CAAC;EACzE,OAAOvB,IAAI,CAACC,SAAS,CAAC4B,mBAAmB,CAAC;AAC9C;AACA;AACA;AACA;AACA;AACA;AACY,MAACC,kBAAkB,GAAGC,KAAA,IAAyE;EAAA,IAAAC,KAAA;EAAA,IAAxE;IAAEC,IAAI;IAAEC,IAAI;IAAEC,WAAW;IAAEtD,MAAM;IAAEuD,WAAW;IAAEX,GAAG;IAAEY;EAAW,CAAG,GAAAN,KAAA;EAClG,IAAIO,QAAQ;EACZ,MAAMC,mBAAmB,IAAAP,KAAA,GAAGG,WAAW,aAAXA,WAAW,cAAXA,WAAW,GAAIF,IAAI,aAAJA,IAAI,uBAAJA,IAAI,CAAEO,IAAI,cAAAR,KAAA,cAAAA,KAAA,GAAI,0BAA0B;EACvF;EACI,IAAII,WAAW,KAAKf,SAAS,EAAE;IAC3BiB,QAAQ,GAAG,QAAQ;EAC3B,OACS;IACDA,QAAQ,GAAGF,WAAW,KAAK,OAAO,GAAG,QAAQ,GAAGA,WAAW;EACnE;EACI,MAAMK,MAAM,MAAAC,MAAA,CAAML,WAAW,OAAAK,MAAA,CAAIR,IAAI,OAAAQ,MAAA,CAAIH,mBAAmB,OAAAG,MAAA,CAAI7D,MAAM,OAAA6D,MAAA,CAAIJ,QAAQ,OAAAI,MAAA,CAAIjB,GAAG,CAAE;EAC3F,IAAIQ,IAAI,EAAE;IACN,UAAAS,MAAA,CAAUT,IAAI,CAACU,IAAI,OAAAD,MAAA,CAAIT,IAAI,CAACW,YAAY,OAAAF,MAAA,CAAID,MAAM;EAC1D,OACS;IACD,OAAOA,MAAM;EACrB;AACA;AACY,MAACI,oBAAoB,GAAG,MAAAA,CAAOnE,qBAAqB,EAAEC,QAAQ,EAAEmE,YAAY,KAAK;EACzF,MAAMC,aAAa,GAAG,MAAM/D,qBAAqB,CAACN,qBAAqB,CAAC;EACxEqE,aAAa,CAACpE,QAAQ,CAAC,GAAAqE,aAAA,CAAAA,aAAA,KAChBF,YAAY;IACfrD,WAAW,EAAEC,IAAI,CAACC,GAAG;EAAE,EAC1B;EACD,MAAMjB,qBAAqB,CAACoB,OAAO,CAACC,mBAAmB,EAAEC,IAAI,CAACC,SAAS,CAAC8C,aAAa,CAAC,CAAC;AAC3F;AACY,MAACjC,kBAAkB,GAAG,MAAAA,CAAOpC,qBAAqB,EAAEC,QAAQ,KAAK;EACzE,MAAMoE,aAAa,GAAG,MAAM/D,qBAAqB,CAACN,qBAAqB,CAAC;EACxE,OAAOqE,aAAa,CAACpE,QAAQ,CAAC;EAC9B,MAAMD,qBAAqB,CAACoB,OAAO,CAACC,mBAAmB,EAAEC,IAAI,CAACC,SAAS,CAAC8C,aAAa,CAAC,CAAC;AAC3F","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}